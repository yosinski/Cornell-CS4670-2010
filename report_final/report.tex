\section{Introduction} % short intro

\edit{Cooper}

Our original proposal was to create a mobile application that will
identify people in an photo using pictures from facebook, and then
poll their information and status and display it in the photo.  This
was to create an augmented reality interface on the mobile device.
However, we quickly found that to create a quality application with
this ability would require more time and resources than we had.

As an alternative, we created a simpler application that utilized a
local database with the goal to find and identify faces in an mobile
image.  This database is created on a desktop computer and copied to
the phone before the application is used.  Our testing utilized two
databases: The Yale Face Database\footnote{Available here:
  http://cvc.yale.edu/projects/yalefaces/yalefaces.html}\cite{YaleFace}
and our own custom database from facebook images.

\section{Related Work} % related work, with references to papers, web pages

Face detection and identification is an active field in computer
vision, and many methods have been developed.  For face detection, one
of the most notable is the ``Viola-Jones'' method, published by Paul
Viola and Michael Jones.\cite{ViolaJones} Their work is based on
AdaBoost\cite{AdaBoost}, improved by cascading classifiers by
complexity - improving speed and accuracy.  The algorithm this project
utilizes for facial detection was developed by Rainer Lienhart and
Jochen Maydt at Intel labs.\cite{Lienhart} Their algorithm adds
rotated Harr-like features to improve accuracy.

Face identification (recognition) methods have existed for decades,
and is continually improving.  One of the oldest methods that has
stood the test of time is Eigenfaces\cite{Eigenfaces}, developed by
Matthew Turk and Alex Pentland, which utilizes Principal Component
Analysis (PCA) for recognition.  This method has been expanded using
Linear Discriminant Analysis (LDA) to improve accuracy, known as
Fisherfaces. \cite{Fisherfaces} Newer facial recognition systems use
3D models\cite{3d}, and were considered for this project, but were
ruled out because the phone has limited computational ability.

\edit{Cooper: copy our references slide}

\section{Approach} % technical description including algorithm

Similar projects to ours have been conducted, such as the Introduction
to Face Detection and Face Recognition by Shervin Emami\cite{Emami}.
Our project was based on this outline in the beginning, and has grown
to include other methods and abilities.  Our project consisted of many
components, which are described in this section.


\edit{Cooper: intro do approach}

\subsection{Detection}



\subsection{Preprocessing}

\edit{Cooper, aka face detection, resizing, grayscale..} 

\subsubsection{Database Generation}
\subsubsection{Eigenvector Generation}



\subsection{Eigenvector Nearest Neighbor}

\edit{Cooper}


\subsection{Fisher Linear Discriminant}

% HERE

Because using nearest neighbors seemed unable to directly classify
faces correctly, we decided to use a more discriminative approach,
namely, the Fisher Linear Discriminant (FLD) \cite{wikiFld}.  FLD
attempts to find the single dimension along which data can be
projected to produce maximum \emph{separation}.  The separation $s$
can be defined as \cite{wikiFld}:

\be
s = \frac{\sigma_{between}^2}{\sigma_{within}^2}= \frac{(\vec w \cdot \vec \mu_{y=1} - \vec w \cdot \vec \mu_{y=0})^2}{\vec w^T \Sigma_{y=1} \vec w + \vec w^T \Sigma_{y=0} \vec w} = \frac{(\vec w \cdot (\vec \mu_{y=1} - \vec \mu_{y=0}))^2}{\vec w^T (\Sigma_{y=0}+\Sigma_{y=1}) \vec w}
\ee

\noindent Intuitively, we project all the data onto a vector $\vec w$,
and then choose $\vec w$ to maximize the distance between the
projected means divided by the sum of the widths of the projected
covariances.  Fortunately, the $\vec w$ that maximizes $s$ can be
calculated in closed form.

\be
\vec w = (\Sigma_{y=0}+\Sigma_{y=1})^{-1}(\vec \mu_{y=1} - \vec \mu_{y=0})
\ee

\noindent In reality, we add a normalizing term to ensure that the sum
of covariance matrices is invertible, so we calculate $\vec w$ as:

\be
\vec w = (\Sigma_{y=0} + \Sigma_{y=1} + \epsilon I)^{-1}(\vec \mu_{y=1} - \vec \mu_{y=0})
\eqlabel{w}
\ee

Finally, Fisher's Linear Discriminant is designed to maximally
separate only two classes from each other.  To work around this
limitation, we train $k$ separate one-vs-all classifiers for each of
the $k$ subjects in our database.  To classify a new test image using
the database, we compute a score for each class and then choose the
class with the highest score.  The score we chose is the following
ratio:

\be
r^{(i)} = \frac{s_{test}^{(i)} - s_{\mu_0}^{(i)}}{s_{\mu_1}^{(i)} - s_{\mu_0}^{(i)}}
\ee


\noindent where $s_{\vec x}^{(i)}$ is the projection of $\vec x$ onto $\vec w$:

\be
s_{\vec x}^{(i)} = \vec w \cdot \vec x
\ee

We could compute the FLD on the raw images, but given our 100 x 100
images we would have to invert a 10,000 by 10,000 dimensional
covariance matrix from \eqref{w} above, which would be both
prohibitively expensive and unnecessary.  Alternately, we can use PCA
to reduce the dimensionality first, and compute $\vec w$ in this space
instead.  This is the approach we ended up using.

To tune the number of eigenvectors used, we compared the performance
using different numbers of eigenvectors on classifying all the
``happy'' faces of the Yale data set.  Results are shown in
\figref{scores_vs_dim}...

\figvarp{scores_vs_dim}{.85}{Caption???}{}




\subsection{Computation Considerations for Mobiles Devices}

\edit{Cooper}

\subsubsection{Load-Time}
\subsubsection{Picture}



\section{Results} % experimental results

\subsection{Face Detection}


Some results using our Haar wavelet detector are shown in
\figref{small_face.jpg} through \figref{three_faces.jpg}.

\figvarp{small_face.jpg}{.60}{Haar wavelet detection of a face taking up
  a small fraction of the image.}{}

\figvarp{small_face_sideways.jpg}{.60}{Our Haar wavelet detector tends
  not to work if the faces are rotated more than 30 degrees.}{}

\figvarp{three_faces.jpg}{.60}{Detection of multiple faces at different
  scales in a single image works well.}{}

\edit{clean this up...}

\subsection{Eigenvector creation}

\edit{pull from slide}

\subsection{Eigenvector Nearest Neighbor results on Yale Data set}

\edit{Cooper}

\subsection{Fisher results on Yale Data set}

\edit{Jason}

\subsection{Fisher results on phone/computer images}

\edit{Jason}


\section{Discussion} % discussion of results, strengths/weaknesses, what worked, what didn't

\edit{Jason}


\section{Future Work} % future work and what you would do if you had more time

\edit{Jason}


\section{Conclusion}

\edit{Cooper}










\section{Results}




\section{Fisher Faces}

Equations from wikipedia:

